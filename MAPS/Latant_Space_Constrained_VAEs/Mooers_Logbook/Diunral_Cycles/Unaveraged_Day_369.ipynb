{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import animation\n",
    "from matplotlib import transforms\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import xarray as xr\n",
    "import dask\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import matplotlib.image as imag\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA,IncrementalPCA\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from matplotlib import ticker\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from statistics import mode\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.stats import norm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator_paper(sample, X, Z):\n",
    "    \n",
    "    fz = 15*1.25\n",
    "    lw = 4\n",
    "    siz = 100\n",
    "    XNNA = 1.25 # Abscissa where architecture-constrained network will be placed\n",
    "    XTEXT = 0.25 # Text placement\n",
    "    YTEXT = 0.3 # Text placement\n",
    "    \n",
    "    plt.rc('text', usetex=False)\n",
    "    matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "    matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "    #mpl.rcParams[\"font.serif\"] = \"STIX\"\n",
    "    plt.rc('font', family='serif', size=fz)\n",
    "    matplotlib.rcParams['lines.linewidth'] = lw\n",
    "    \n",
    "    \n",
    "    cmap=\"RdBu_r\"\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15,6))\n",
    "    cs0 = ax.pcolor(X, Z, sample, cmap=cmap, vmin=-1.0, vmax = 1.0)\n",
    "    ax.set_title(\"Anomalous Vertical Velocity Field Detected By ELBO\")\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    ax.set_xlabel(\"CRMs\", fontsize=fz*1.5)\n",
    "    ax.xaxis.set_label_coords(0.54,-0.05)\n",
    "    h = ax.set_ylabel(\"hPa\", fontsize = fz*1.5)\n",
    "    h.set_rotation(0)\n",
    "    ax.yaxis.set_label_coords(-0.10,0.44)\n",
    "    #y_ticks = np.arange(1350, 0, -350)\n",
    "    #ax.set_yticklabels(y_ticks, fontsize=fz*1.33)\n",
    "    ax.tick_params(axis='x', labelsize=fz*1.33)\n",
    "    ax.tick_params(axis='y', labelsize=fz*1.33)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(cs0, cax=cax)\n",
    "    cbar.set_label(label=r'$\\left(\\mathrm{m\\ s^{-1}}\\right)$', rotation=\"horizontal\", fontsize=fz*1.5, labelpad=30, y = 0.65)\n",
    "    plt.show()\n",
    "    #plt.savefig(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/CI_Figure_Data/Anomaly.pdf\")\n",
    "    \n",
    "#plot_generator(test[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 15*1.5\n",
    "lw = 4\n",
    "siz = 100\n",
    "XNNA = 1.25 # Abscissa where architecture-constrained network will be placed\n",
    "XTEXT = 0.25 # Text placement\n",
    "YTEXT = 0.3 # Text placement\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "#mpl.rcParams[\"font.serif\"] = \"STIX\"\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "matplotlib.rcParams['lines.linewidth'] = lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = netCDF4.Dataset(\"/fast/gmooers/Raw_Data/extras/TimestepOutput_Neuralnet_SPCAM_216.cam.h1.2009-01-01-00000.nc\")\n",
    "levs = np.array(others.variables['lev'])\n",
    "lons = np.array(others.variables['lon'])\n",
    "new = np.flip(levs)\n",
    "crms = np.arange(1,129,1)\n",
    "Xs, Zs = np.meshgrid(crms, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diurnal_Amazon_W_Test_2D = np.load(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/Synoptic_Latent_Spaces/Single_Day_2D_PCA_Latent_Space__369.npy\")\n",
    "Diurnal_Atlantic_W_Test_2D = np.load(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/Synoptic_Latent_Spaces/Atlantic_Day_2D_PCA_Latent_Space__369.npy\")\n",
    "\n",
    "z_test_tsne = np.load(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/Synoptic_Latent_Spaces/Full_Trackable_2D_PCA_Latent_Space__369.npy\")\n",
    "\n",
    "\n",
    "Test_Images = np.load(\"/fast/gmooers/Preprocessed_Data/Single_Amazon_Unaveraged/w_var_test_day.npy\")\n",
    "Ocean_Test_Images = np.load(\"/fast/gmooers/Preprocessed_Data/Single_Amazon_Unaveraged/w_var_atlantic_test_day.npy\")\n",
    "All_Test_Images = np.load(\"/fast/gmooers/Preprocessed_Data/W_Variable/Space_Time_W_Test.npy\")\n",
    "Max_Scalar = np.load(\"/fast/gmooers/Preprocessed_Data/W_Variable/Space_Time_Max_Scalar.npy\")\n",
    "Min_Scalar = np.load(\"/fast/gmooers/Preprocessed_Data/W_Variable/Space_Time_Min_Scalar.npy\")\n",
    "Test_Images = np.interp(Test_Images, (0, 1), (Min_Scalar, Max_Scalar))\n",
    "All_Test_Images = np.interp(All_Test_Images, (0, 1), (Min_Scalar, Max_Scalar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.hsv(np.linspace(0, 1, int(len(Diurnal_Amazon_W_Test_2D)/4)))\n",
    "bc_labels = [\"0\",\"1\",\"2\",\"3\", \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"]\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "ax.scatter(x=z_test_tsne[:, 0], y=z_test_tsne[:, 1], c=\"black\", s=0.2)\n",
    "count = -1\n",
    "for i in range(len(Diurnal_Amazon_W_Test_2D)):\n",
    "    if i%4 == 0:\n",
    "        count = count+1\n",
    "        cb = ax.scatter(x=Diurnal_Amazon_W_Test_2D[i, 0], y=Diurnal_Amazon_W_Test_2D[i, 1], c=colors[count], s=400, label=str(int(i/4)))\n",
    "    else:\n",
    "        cb = ax.scatter(x=Diurnal_Amazon_W_Test_2D[i, 0], y=Diurnal_Amazon_W_Test_2D[i, 1], c=colors[count], s=400)\n",
    "        \n",
    "#ax.legend(bbox_to_anchor=(0.999, 1.00))\n",
    "ax.legend(loc=\"best\", ncol=4, fontsize=fz*0.75)\n",
    "#ax.legend(loc=\"lower left\", mode = \"expand\", ncol=24, fontsize=fz/2)\n",
    "ax.set_title(\"Latent Space from Amazon Average Diurnal Cycle Colored by LST Hour\", fontsize=fz*2)\n",
    "\n",
    "#plt.savefig(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/CI_Figure_Data/Amazon.pdf\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.hsv(np.linspace(0, 1, int(len(Diurnal_Amazon_W_Test_2D)/4)))\n",
    "bc_labels = [\"0\",\"1\",\"2\",\"3\", \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"]\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "ax.scatter(x=z_test_tsne[:, 0], y=z_test_tsne[:, 1], c=\"black\", s=0.2)\n",
    "count = -1\n",
    "for i in range(len(Diurnal_Amazon_W_Test_2D)):\n",
    "    if i%4 == 0:\n",
    "        count = count+1\n",
    "        cb = ax.scatter(x=Diurnal_Amazon_W_Test_2D[i, 0], y=Diurnal_Amazon_W_Test_2D[i, 1], c=colors[count], s=400, label=str(int(i/4)))\n",
    "    else:\n",
    "        cb = ax.scatter(x=Diurnal_Amazon_W_Test_2D[i, 0], y=Diurnal_Amazon_W_Test_2D[i, 1], c=colors[count], s=400)\n",
    "        \n",
    "#ax.legend(bbox_to_anchor=(0.999, 1.00))\n",
    "ax.legend(loc=\"best\", ncol=4, fontsize=fz*0.75)\n",
    "#ax.legend(loc=\"lower left\", mode = \"expand\", ncol=24, fontsize=fz/2)\n",
    "ax.set_title(\"Latent Space from Amazon Average Diurnal Cycle Colored by LST Hour\", fontsize=fz*2)\n",
    "\n",
    "#plt.savefig(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/CI_Figure_Data/Amazon.pdf\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.hsv(np.linspace(0, 1, int(len(Diurnal_Amazon_W_Test_2D)/4)))\n",
    "bc_labels = [\"0\",\"1\",\"2\",\"3\", \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"]\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "ax.scatter(x=z_test_tsne[:, 0], y=z_test_tsne[:, 1], c=\"black\", s=0.2)\n",
    "count = -1\n",
    "for i in range(len(Diurnal_Atlantic_W_Test_2D)):\n",
    "    if i%4 == 0:\n",
    "        count = count+1\n",
    "        cb = ax.scatter(x=Diurnal_Atlantic_W_Test_2D[i, 0], y=Diurnal_Atlantic_W_Test_2D[i, 1], c=colors[count], s=400, label=str(int(i/4)))\n",
    "    else:\n",
    "        cb = ax.scatter(x=Diurnal_Atlantic_W_Test_2D[i, 0], y=Diurnal_Atlantic_W_Test_2D[i, 1], c=colors[count], s=400)\n",
    "        \n",
    "#ax.legend(bbox_to_anchor=(0.999, 1.00))\n",
    "ax.legend(loc=\"best\", ncol=4, fontsize=fz*0.75)\n",
    "#ax.legend(loc=\"lower left\", mode = \"expand\", ncol=24, fontsize=fz/2)\n",
    "ax.set_title(\"Latent Space from Amazon Average Diurnal Cycle Colored by LST Hour\", fontsize=fz*2)\n",
    "\n",
    "#plt.savefig(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/CI_Figure_Data/Amazon.pdf\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Images_Reorganized = np.zeros(shape=(int(len(All_Test_Images)/(22*144)),30,128,22,144))\n",
    "Test_Latents_Reorganized = np.zeros(shape=(int(len(z_test_tsne_track)/(22*144)),2,22,144))\n",
    "Test_Images_LST_Labels = np.zeros(shape=(96,30,128,22,144))\n",
    "Test_Latents_LST_Labels = np.zeros(shape=(96,2,22,144))\n",
    "Test_Images_LST_Labels_Sorted = np.zeros(shape=(96,30,128,22,144))\n",
    "Test_Latents_LST_Labels_Sorted = np.zeros(shape=(96,2,22,144))\n",
    "filler = np.arange(0,96,1)\n",
    "filler_a = filler[:64]\n",
    "filler_b = filler[64:]\n",
    "filler = np.concatenate((filler_b, filler_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(Test_Images_Reorganized)):\n",
    "    for j in range(len(Test_Images_Reorganized[0][0][0])): \n",
    "        for k in range(len(Test_Images_Reorganized[0][0][0][0])): \n",
    "            Test_Images_Reorganized[i,:,:,j,k] = All_Test_Images[count,:,:]\n",
    "            Test_Latents_Reorganized[i,:,j,k] = z_test_tsne_track[count,:]\n",
    "            count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(Test_Images_LST_Labels[0])):\n",
    "    for j in range(len(Test_Images_LST_Labels[0][0])): \n",
    "        for k in range(len(Test_Images_LST_Labels[0][0][0])): \n",
    "            for l in range(len(Test_Images_LST_Labels[0][0][0][0])):\n",
    "                Test_Images_LST_Labels[:,i,j,k,l] = filler\n",
    "                count = count+1\n",
    "            \n",
    "count = 0\n",
    "for i in range(len(Test_Latents_LST_Labels[0])):\n",
    "    for j in range(len(Test_Latents_LST_Labels[0][0])): \n",
    "        for k in range(len(Test_Latents_LST_Labels[0][0][0])): \n",
    "            Test_Latents_LST_Labels[:,i,j,k] = filler\n",
    "            count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Test_Images_LST_Labels[0][0][0][0])):\n",
    "    splitter = int(round((lons[i]/360.)*96.))\n",
    "    part_a = Test_Images_LST_Labels[:-splitter,:,:,:,i]\n",
    "    part_b = Test_Images_LST_Labels[-splitter:,:,:,:,i]\n",
    "    combined = np.concatenate((part_b, part_a), axis=0)\n",
    "    Test_Images_LST_Labels_Sorted[:,:,:,:,i] = combined\n",
    "    \n",
    "    part_a = Test_Latents_LST_Labels[:-splitter,:,:,i]\n",
    "    part_b = Test_Latents_LST_Labels[-splitter:,:,:,i]\n",
    "    combined = np.concatenate((part_b, part_a), axis=0)\n",
    "    Test_Latents_LST_Labels_Sorted[:,:,:,i] = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Test_Images_LST_Labels[0][0][0][0])):\n",
    "    splitter = int(round((lons[i]/360.)*96.))\n",
    "    part_a = Test_Images_LST_Labels[splitter:,:,:,:,i]\n",
    "    part_b = Test_Images_LST_Labels[:splitter,:,:,:,i]\n",
    "    combined = np.concatenate((part_a, part_b), axis=0)\n",
    "    Test_Images_LST_Labels_Sorted[:,:,:,:,i] = combined\n",
    "    \n",
    "    part_a = Test_Latents_LST_Labels[splitter:,:,:,i]\n",
    "    part_b = Test_Latents_LST_Labels[:splitter,:,:,i]\n",
    "    combined = np.concatenate((part_a, part_b), axis=0)\n",
    "    Test_Latents_LST_Labels_Sorted[:,:,:,i] = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_LST_Image_Labels = Test_Images_LST_Labels_Sorted[:16,:,:,:,:]\n",
    "Final_LST_Latent_Labels = Test_Latents_LST_Labels_Sorted[:16,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Final_LST_Latent_Labels[0][0][0])):\n",
    "    print(Final_LST_Latent_Labels[:,0,0,i], lons[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Truly_Final_LST_Image_Labels = np.empty(All_Test_Images.shape)\n",
    "Truly_Final_LST_Latent_Labels = np.empty(z_test_tsne_track.shape)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(Final_LST_Image_Labels)):\n",
    "    for j in range(len(Final_LST_Image_Labels[0][0][0])):\n",
    "        for k in range(len(Final_LST_Image_Labels[0][0][0][0])):\n",
    "            Truly_Final_LST_Image_Labels[count,:,:] = Final_LST_Image_Labels[i,:,:,j,k]\n",
    "            count = count+1\n",
    "            \n",
    "count = 0\n",
    "for i in range(len(Final_LST_Latent_Labels)):\n",
    "    for j in range(len(Final_LST_Latent_Labels[0][0])):\n",
    "        for k in range(len(Final_LST_Latent_Labels[0][0][0])):\n",
    "            Truly_Final_LST_Latent_Labels[count,:] = Final_LST_Latent_Labels[i,:,j,k]\n",
    "            count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Useful_LTS_Labels = Truly_Final_LST_Latent_Labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.hsv(np.linspace(0, 1, int(len(Diurnal_Amazon_W_Test_2D)/4)))\n",
    "bc_labels = [\"0\",\"1\",\"2\",\"3\", \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"]\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "obs = []\n",
    "for i in range(10000):\n",
    "#for i in range(len(z_test_tsne_track)):\n",
    "    if i %1000 == 0:\n",
    "        print(i)\n",
    "    if int(Useful_LTS_Labels[i]/4) not in obs:\n",
    "        obs.append(int(Useful_LTS_Labels[i]/4))\n",
    "        ax.scatter(x=z_test_tsne_track[i, 0], y=z_test_tsne_track[i, 1], c=colors[int(Useful_LTS_Labels[i]/4)], s=10.0, label = str(int(Useful_LTS_Labels[i]/4)))\n",
    "    else:\n",
    "        ax.scatter(x=z_test_tsne_track[i, 0], y=z_test_tsne_track[i, 1], c=colors[int(Useful_LTS_Labels[i]/4)], s=10.0)\n",
    "        \n",
    "       \n",
    "\n",
    "lgnd = ax.legend(loc=\"best\", ncol=4, fontsize=fz*0.75)\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([200.0])\n",
    "    \n",
    "    \n",
    "count = -1\n",
    "for i in range(len(Diurnal_Amazon_W_Test_2D)):\n",
    "    if i%4 == 0:\n",
    "        count = count+1\n",
    "        cb = ax.scatter(x=Diurnal_Amazon_W_Test_2D[i, 0], y=Diurnal_Amazon_W_Test_2D[i, 1], c=colors[count], s=400, label=str(int(i/4)))\n",
    "    else:\n",
    "        cb = ax.scatter(x=Diurnal_Amazon_W_Test_2D[i, 0], y=Diurnal_Amazon_W_Test_2D[i, 1], c=colors[count], s=400)\n",
    " \n",
    "#ax.legend(loc=\"lower left\", mode = \"expand\", ncol=24, fontsize=fz/2)\n",
    "ax.set_title(\"Latent Space from Amazon Average Diurnal Cycle Colored by LST Hour\", fontsize=fz*2)\n",
    "\n",
    "#plt.savefig(\"/fast/gmooers/gmooers_git/CBRAIN-CAM/MAPS/CI_Figure_Data/Amazon.pdf\")\n",
    "print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
