{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import xarray as xr\n",
    "import dask\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data sample.  This one has already been spliced by lat/lon and Vertical Velocity pulled out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/DFS-L/DATA/pritchard/gmooers/Workflow/MAPS/SPCAM/Small_Sample/Data_Points/One_Day_Merged_Data.nc'\n",
    "real_ds = xr.open_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_velocity = real_ds['CRM_W'].values\n",
    "w_velocity = np.squeeze(w_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 96, 30, 128)\n"
     ]
    }
   ],
   "source": [
    "print(w_velocity.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time I want to shuffle in both space and time, so I will combine the first two dimensions using the reshape function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = len(w_velocity[0])\n",
    "coords = len(w_velocity)\n",
    "lev = len(w_velocity[0][0])\n",
    "crm_x = len(w_velocity[0][0][0])\n",
    "w_new = np.reshape(w_velocity, (coords*t, lev, crm_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(w_new).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Morphology Tests, e.g. feeding in low resolution image snap shots, I do not want a diurnal cycle, so I will shuffle by time:\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/random/shuffle\n",
    "\n",
    "I seem to need to use a tensorflow built in function to do this on an array more than two dimensions...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/gmooers/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_shuffled = tf.random.shuffle(w_new, seed=None, name=None)\n",
    "sess = tf.InteractiveSession()\n",
    "w_numpy = w_shuffled.eval()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to split data into training and test sections:\n",
    "\n",
    "Will do an 80/20 split for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = w_numpy[:int(4*len(w_numpy)/5),:,:]\n",
    "w_test = w_numpy[int(4*len(w_numpy)/5):,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must scale all array values to between 0 and 1\n",
    "\n",
    "Seems standardization not normalization is apropriate\n",
    "- both training and validation data\n",
    "\n",
    "https://stats.stackexchange.com/questions/10289/whats-the-difference-between-normalization-and-standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1:\n",
    "\n",
    "Assign z scores centered around $\\mu$ of 0 and $\\sigma$ = 1\n",
    "Standardization:\n",
    "\n",
    "$X^` = \\frac{x - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_train = (w_train - w_train.mean(axis=(1,2),keepdims=1)) / w_train.std(axis=(1,2),keepdims=1)\n",
    "rescaled_test = (w_test - w_test.mean(axis=(1,2),keepdims=1)) / w_test.std(axis=(1,2),keepdims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2:\n",
    "\n",
    "Normalization: Scale each value in arrray between 0 to 1.  This seems to be method of choice in most \"image\" problems where they divide by 255. to get pixels between 0 and 1, so I will defer to it for now?\n",
    "\n",
    "$X^` = \\frac{x - min(x)}{max(x)-min(x)}$\n",
    "\n",
    "The built in interpolation function will allow this to easily be done in a line of code\n",
    "\n",
    "https://stackoverflow.com/questions/36000843/scale-numpy-array-to-certain-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_train = np.interp(w_train, (w_train.min(), w_train.max()), (0, +1))\n",
    "rescaled_test = np.interp(w_test, (w_train.min(), w_train.max()), (0, +1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as .npy files for VAE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/fast/gmooers/Preprocessed_Data/W_Trial/Space_Time_W_Training.npy', rescaled_train)\n",
    "np.save('/fast/gmooers/Preprocessed_Data/W_Trial/Space_Time_W_Test.npy', rescaled_test)\n",
    "np.save('/fast/gmooers/Preprocessed_Data/W_Trial/Space_Time_Max_Scalar.npy', w_train.max())\n",
    "np.save('/fast/gmooers/Preprocessed_Data/W_Trial/Space_Time_Min_Scalar.npy', w_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.75107 21.606749\n",
      "0.032688401774891476 0.9060817235862667\n"
     ]
    }
   ],
   "source": [
    "print(np.min(w_test), np.max(w_test))\n",
    "print(np.min(rescaled_test), np.max(rescaled_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_test = np.interp(rescaled_test, (0, 1), (w_train.min(), w_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.751070022583008 21.606748580932617\n"
     ]
    }
   ],
   "source": [
    "print(np.min(unscaled_test), np.max(unscaled_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
